{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f9832582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from dynamic_object_detection.params import *\n",
    "import yaml\n",
    "import robotdatapy as rdp\n",
    "\n",
    "os.environ['BAG_PATH'] = '/home/andyli/Downloads/may11_cv2_gt_slow_2025-05-11-19-48-01.bag'\n",
    "\n",
    "time_tol = 10.0 # s\n",
    "vel_estimate_dt = 0.5 # s\n",
    "detected_threshold = 1.0 # m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f504ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL = 'out/hamilton1'\n",
    "\n",
    "\n",
    "gt_bag = '~/Downloads/husky_gt_3/'\n",
    "gt_topic = lambda obj: f'/{obj}/world'\n",
    "cam = 'Husky'\n",
    "objs = ['BD01', 'SCOUT2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "33a7954b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'avg_batch_time': 2.527722447751516,\n",
       " 'avg_frame_time': 0.10532176865631317,\n",
       " 'total_time': 209.80096316337585}"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "results_path = os.path.join('..', f'{EVAL}.pkl')\n",
    "params_path = os.path.join('..', f'{EVAL}.yaml')\n",
    "\n",
    "with open(results_path, 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "params = Params.from_yaml(params_path)\n",
    "\n",
    "cam_pose_data = rdp.data.PoseData.from_bag(\n",
    "    path=gt_bag,\n",
    "    topic=gt_topic(cam),\n",
    "    time_tol=time_tol,\n",
    "    T_postmultiply=params.pose_data_params.T_odom_camera\n",
    ")\n",
    "\n",
    "obj_pose_data = [\n",
    "    rdp.data.PoseData.from_bag(\n",
    "        path=gt_bag,\n",
    "        topic=gt_topic(obj),\n",
    "        time_tol=time_tol,\n",
    "    ) for obj in objs\n",
    "]\n",
    "\n",
    "cam_info = results['camera_info']\n",
    "\n",
    "results['runtime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "99ddb382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project(obj_pos, cam_info):\n",
    "    obj_pixel = cam_info['K'] @ obj_pos\n",
    "    obj_pixel /= obj_pixel[2]\n",
    "    obj_pixel = obj_pixel[:2]\n",
    "\n",
    "    return obj_pixel\n",
    "\n",
    "def within_cam_view(T_cam_obj, cam_info):\n",
    "    obj_pos = T_cam_obj[:3, 3]\n",
    "\n",
    "    if obj_pos[2] <= 0: return False\n",
    "\n",
    "    obj_pixel = project(obj_pos, cam_info)\n",
    "\n",
    "    return 0 <= obj_pixel[0] <= cam_info['W'] and \\\n",
    "           0 <= obj_pixel[1] <= cam_info['H']\n",
    "\n",
    "def estimate_vel(pose_data, t, dt):\n",
    "    idx1 = pose_data.idx(t - dt, force_single=True)\n",
    "    idx2 = pose_data.idx(t + dt, force_single=True)\n",
    "\n",
    "    if idx1 == idx2: return None\n",
    "\n",
    "    t1 = pose_data.times[idx1]\n",
    "    t2 = pose_data.times[idx2]\n",
    "    pose1 = pose_data.pose(t1)\n",
    "    pose2 = pose_data.pose(t2)\n",
    "\n",
    "    return np.linalg.norm(pose2[:3, 3] - pose1[:3, 3]) / (t2 - t1)\n",
    "\n",
    "def get_min_vel(params, z):\n",
    "    return params.tracking_params.min_vel_threshold + z * params.tracking_params.vel_threshold_gain\n",
    "\n",
    "def mahalanobis_distance(detected_obj_pos, detected_obj_cov, obj_pos):\n",
    "    diff = detected_obj_pos - obj_pos\n",
    "    return np.sqrt(diff.T @ np.linalg.inv(detected_obj_cov) @ diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "4ea1956c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 848 dynamic objects in frames, 671 were detected: 79.13%. 20.87% false negatives.\n",
      "Out of 932 detected dynamic objects, 681 were correct detections: 73.07%. 26.93% false positives.\n",
      "Average error 0.2506625641711769 m\n"
     ]
    }
   ],
   "source": [
    "total_should_have_detected_objects = 0\n",
    "total_detected_objects = 0\n",
    "\n",
    "total_objects = 0\n",
    "total_correct_detections = 0\n",
    "\n",
    "total_detected_error = 0\n",
    "total_detected_error_count = 0\n",
    "\n",
    "for frame, time in enumerate(results['times']):\n",
    "\n",
    "    try:\n",
    "        cam_pose = cam_pose_data.pose(time)\n",
    "        for i, obj in enumerate(objs):\n",
    "            obj_pose = obj_pose_data[i].pose(time)\n",
    "            T_cam_obj = np.linalg.inv(cam_pose) @ obj_pose\n",
    "\n",
    "            if T_cam_obj[2, 3] > params.depth_data_params.max_depth: continue\n",
    "            if not within_cam_view(T_cam_obj, cam_info): continue\n",
    "\n",
    "            estimated_vel = estimate_vel(obj_pose_data[i], time, vel_estimate_dt)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    cam_pose = cam_pose_data.pose(time)\n",
    "\n",
    "    frame_objs = results['objects'][frame]\n",
    "\n",
    "    total_objects += len(frame_objs)\n",
    "\n",
    "    correct_detection = [False] * len(frame_objs)\n",
    "\n",
    "    for i, obj in enumerate(objs):\n",
    "\n",
    "        obj_pose = obj_pose_data[i].pose(time)\n",
    "        T_cam_obj = np.linalg.inv(cam_pose) @ obj_pose\n",
    "        Z = T_cam_obj[2, 3]\n",
    "\n",
    "        if Z > params.depth_data_params.max_depth: continue\n",
    "        if not within_cam_view(T_cam_obj, cam_info): continue\n",
    "\n",
    "        try:\n",
    "            estimated_vel = estimate_vel(obj_pose_data[i], time, vel_estimate_dt)\n",
    "        except:\n",
    "            continue\n",
    "        if estimated_vel is None: continue\n",
    "\n",
    "        if estimated_vel >= get_min_vel(params, Z):\n",
    "\n",
    "            false_negative = True\n",
    "\n",
    "            for j, detected_obj in enumerate(frame_objs):\n",
    "                if np.linalg.norm(detected_obj['point'] - T_cam_obj[:3, 3]) < detected_threshold:\n",
    "                    false_negative = False\n",
    "                    correct_detection[j] = True\n",
    "\n",
    "                    total_detected_error += np.linalg.norm(detected_obj['point'] - T_cam_obj[:3, 3])\n",
    "                    total_detected_error_count += 1\n",
    "\n",
    "            if false_negative:\n",
    "                total_should_have_detected_objects += 1\n",
    "            else:\n",
    "                total_detected_objects += 1\n",
    "\n",
    "    total_correct_detections += sum(correct_detection)\n",
    "\n",
    "det_rate = total_detected_objects / (total_detected_objects + total_should_have_detected_objects)\n",
    "print(f'Out of {total_should_have_detected_objects + total_detected_objects} dynamic objects in frames, {total_detected_objects} were detected: {det_rate * 100:.2f}%. {(1- det_rate) * 100:.2f}% false negatives.')\n",
    "correct_rate = total_correct_detections / total_objects \n",
    "print(f'Out of {total_objects} detected dynamic objects, {total_correct_detections} were correct detections: {correct_rate * 100:.2f}%. {(1 - correct_rate) * 100:.2f}% false positives.')\n",
    "print(f'Average error {total_detected_error / total_detected_error_count} m')\n",
    "        \n",
    "                    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
